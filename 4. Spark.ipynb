{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9d21a5fa-c265-4ac4-9713-17256d4fd165",
   "metadata": {},
   "source": [
    "# SPARK"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "093dccbd-e890-4bf0-bf14-c033cb87efb7",
   "metadata": {},
   "source": [
    "# Task 1.\n",
    "### Initialize the Spark session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4c9e1d3f-a25e-4d13-9df9-c87904dbe875",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.3.0\n"
     ]
    }
   ],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "import pyspark \n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "\n",
    "print(spark.version)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "260a2363-ff36-43ec-aff3-80b2037db642",
   "metadata": {},
   "source": [
    "# Task 2.\n",
    "- generate collection with number from 1 to 20\n",
    "- print this collection\n",
    "- print collection size\n",
    "- sum all numbers\n",
    "- calculate average\n",
    "- print numbers greater than average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "91eec090-38a6-4330-990f-c9b6550767d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collection: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20]\n",
      "Collection size: 20\n",
      "Sum numbers in collection: 210\n",
      "Average: 10.5\n",
      "Numbers greater than average: [11, 12, 13, 14, 15, 16, 17, 18, 19, 20]\n"
     ]
    }
   ],
   "source": [
    "numbers = spark.range(1,21).rdd.map(lambda el: el.id)\n",
    "\n",
    "# print collection\n",
    "print(f'Collection: {numbers.collect()}')\n",
    "\n",
    "# collection size\n",
    "collectionSize = numbers.count()\n",
    "print(f'Collection size: {collectionSize}')\n",
    "\n",
    "# sum of elements\n",
    "sum = numbers.reduce(lambda x,y: x+y)\n",
    "print(f'Sum numbers in collection: {sum}')\n",
    "\n",
    "# calc. average\n",
    "average = sum/collectionSize\n",
    "print(f'Average: {average}')\n",
    "\n",
    "# numbers greater than average\n",
    "greater = numbers.filter(lambda el: el > average).collect()\n",
    "print(f'Numbers greater than average: {greater}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04ff89d1-db4f-42fb-bd57-9f5c55402451",
   "metadata": {},
   "source": [
    "# Task 3.\n",
    "- read file and load content to collection\n",
    "- print collection size\n",
    "- show first five lines\n",
    "- create new collection with lines containing the word **Spark** and print first three lines from this collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1d28210f-b204-4dac-b619-db9433d3edda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "108\n",
      "['# Apache Spark', '', 'Spark is a unified analytics engine for large-scale data processing. It provides', 'high-level APIs in Scala, Java, Python, and R, and an optimized engine that', 'supports general computation graphs for data analysis. It also supports a']\n",
      "19\n",
      "['# Apache Spark', 'Spark is a unified analytics engine for large-scale data processing. It provides', 'rich set of higher-level tools including Spark SQL for SQL and DataFrames,']\n"
     ]
    }
   ],
   "source": [
    "data = spark.sparkContext.textFile(\"textfile.md\")\n",
    "\n",
    "# collection size\n",
    "print(data.count())\n",
    "\n",
    "# show first five lines\n",
    "print(data.take(5))\n",
    "\n",
    "# create new collection with lines containing the word \"Spark\"\n",
    "dataSpark = data.filter(lambda el: el.find(\"Spark\") != -1)\n",
    "\n",
    "# new collection size\n",
    "print(dataSpark.count())\n",
    "\n",
    "# print first three lines from this collection\n",
    "print(dataSpark.take(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d25dcd3-d755-4a2f-a035-262cfce53f8e",
   "metadata": {},
   "source": [
    "# Task 4.\n",
    "- count all characters in the \"data\" collection\n",
    "- count all characters in the \"dataSpark\" collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "263c9beb-668a-4f5c-8c6d-8072728244eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4380\n",
      "1507\n"
     ]
    }
   ],
   "source": [
    "print(data.map(lambda el: len(el)).reduce(lambda x,y: x+y))\n",
    "\n",
    "print(dataSpark.map(lambda el: len(el)).reduce(lambda x,y: x+y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7adf33ad-7d9c-4cda-b558-1f6a5280f76f",
   "metadata": {},
   "source": [
    "# Task 5.\n",
    "- create new collection with lines containing the word **example**\n",
    "- print this collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9fb8d1e9-42db-4d37-9411-b3881b584850",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['To build Spark and its example programs, run:', 'Spark also comes with several sample programs in the `examples` directory.', 'To run one of them, use `./bin/run-example <class> [params]`. For example:', '    ./bin/run-example SparkPi', 'will run the Pi example locally.', 'You can set the MASTER environment variable when running examples to submit', 'examples to a cluster. This can be a mesos:// or spark:// URL,', 'can also use an abbreviated class name if the class is in the `examples`', '    MASTER=spark://host:7077 ./bin/run-example SparkPi', 'Many of the example programs print usage help if no params are given.']\n"
     ]
    }
   ],
   "source": [
    "dataExample = data.filter(lambda el: el.find(\"example\") != -1)\n",
    "\n",
    "print(dataExample.collect())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43949ee5-34a8-4201-8e6e-9f55c0c9df5d",
   "metadata": {},
   "source": [
    "# Task 6.\n",
    "- read file **people.json** and load content to dataset\n",
    "- print dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ff09cf32-fb96-4ab9-8e20-f7b8020dca29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+\n",
      "|age|   name|\n",
      "+---+-------+\n",
      "| 18| Michał|\n",
      "| 30|Andrzej|\n",
      "| 19| Tomasz|\n",
      "| 24|   Ania|\n",
      "| 32|  Basia|\n",
      "| 19|  Iwona|\n",
      "| 22| Monika|\n",
      "| 17| Marcin|\n",
      "| 31| Łukasz|\n",
      "+---+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ds = spark.read.json(\"people.json\")\n",
    "ds.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a60a6193-e05b-4536-a6ef-bd3d6b8a0ccc",
   "metadata": {},
   "source": [
    "# Task 7.\n",
    "- print only \"name\" column using SQL and HiveSQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "141c3f0c-1352-400b-8494-31d4af35807a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+\n",
      "|   name|\n",
      "+-------+\n",
      "| Michał|\n",
      "|Andrzej|\n",
      "| Tomasz|\n",
      "|   Ania|\n",
      "|  Basia|\n",
      "|  Iwona|\n",
      "| Monika|\n",
      "| Marcin|\n",
      "| Łukasz|\n",
      "+-------+\n",
      "\n",
      "+-------+\n",
      "|   name|\n",
      "+-------+\n",
      "| Michał|\n",
      "|Andrzej|\n",
      "| Tomasz|\n",
      "|   Ania|\n",
      "|  Basia|\n",
      "|  Iwona|\n",
      "| Monika|\n",
      "| Marcin|\n",
      "| Łukasz|\n",
      "+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import *\n",
    "\n",
    "ds.createOrReplaceTempView(\"ds\")\n",
    "\n",
    "# using SQL dialect\n",
    "spark.sql(\"SELECT name FROM ds\").show()\n",
    "\n",
    "# using HiveSQL dialect\n",
    "ds.select(\"name\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02c6827c-1120-4e0c-87a6-28fb25eb2ab1",
   "metadata": {},
   "source": [
    "# Task 8."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c48cf1ca-dde5-4e45-a097-19ca52b74ef3",
   "metadata": {},
   "source": [
    "### 8.1. Display people who who are older than 21 years old"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8d95f02a-4210-4abb-bff6-22e2084bf966",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+\n",
      "|age|   name|\n",
      "+---+-------+\n",
      "| 30|Andrzej|\n",
      "| 24|   Ania|\n",
      "| 32|  Basia|\n",
      "| 22| Monika|\n",
      "| 31| Łukasz|\n",
      "+---+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ds.filter(ds.age>21).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0827eff-1b40-42d5-8d4b-f4ddfbe2f7f2",
   "metadata": {},
   "source": [
    "### 8.2. Display average age."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9904ea54-fb51-4b53-901b-ac92f15f44ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "|          avg(age)|\n",
      "+------------------+\n",
      "|23.555555555555557|\n",
      "+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ds.select(avg(\"age\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b2122f9-da87-46c4-924e-329673e1b5d8",
   "metadata": {},
   "source": [
    "### 8.3. Display names that begin with the letter A."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5e8d4827-e1c3-4a0a-8a17-5bfc0a5899b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+\n",
      "|   name|\n",
      "+-------+\n",
      "|Andrzej|\n",
      "|   Ania|\n",
      "+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ds.filter(col(\"name\").like(\"A%\")).select(\"name\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2761b3ff-8897-4e1c-9cf6-9f8c5838bda7",
   "metadata": {},
   "source": [
    "### 8.4. Display age of the youngest and oldest person."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0d35fbf1-0e22-4479-aa8d-89699bed7490",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+\n",
      "|Youngest|Oldest|\n",
      "+--------+------+\n",
      "|      17|    32|\n",
      "+--------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ds.select(min(\"age\").alias(\"Youngest\"), max(\"age\").alias(\"Oldest\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dc73cbf-c092-48f8-a9a1-b9287d01e17f",
   "metadata": {},
   "source": [
    "### 8.5. Calculate average age, show people younger and older than average age."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "644e61ea-7661-4987-8352-31102c451a33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average age: 23\n",
      "People younger than average age:\n",
      "+---+------+\n",
      "|age|  name|\n",
      "+---+------+\n",
      "| 18|Michał|\n",
      "| 19|Tomasz|\n",
      "| 19| Iwona|\n",
      "| 22|Monika|\n",
      "| 17|Marcin|\n",
      "+---+------+\n",
      "\n",
      "People older than average age:\n",
      "+---+-------+\n",
      "|age|   name|\n",
      "+---+-------+\n",
      "| 30|Andrzej|\n",
      "| 24|   Ania|\n",
      "| 32|  Basia|\n",
      "| 31| Łukasz|\n",
      "+---+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "averageAge = ds.select(avg('age').cast(\"int\")).collect()[0][0]\n",
    "\n",
    "print(f'Average age: {averageAge}')\n",
    "\n",
    "print(\"People younger than average age:\")\n",
    "ds.filter(ds.age < averageAge).show()\n",
    "\n",
    "print(\"People older than average age:\")\n",
    "ds.filter(ds.age > averageAge).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ace723fb-7a26-40ee-98d3-94d31f2ed754",
   "metadata": {},
   "source": [
    "# Task 9.\n",
    "- import class Person from file \"Person.py\"\n",
    "- import data from 'adult.data'\n",
    "- count elements\n",
    "- print first element"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6a69ca85-c755-4d4d-986b-df189723dd36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30162\n",
      "{'age': 39, 'workclass': 'State-gov', 'fnlwgt': '77516', 'education': 'Bachelors', 'educationNum': 13, 'maritalStatus': 'Never-married', 'occupation': 'Adm-clerical', 'relationship': 'Not-in-family', 'race': 'White', 'sex': 'Male', 'capitalGain': '2174', 'capitalLoss': '0', 'hoursPerWeek': 40, 'nativeCountry': 'United-States', 'gainClass': '<=50K'}\n"
     ]
    }
   ],
   "source": [
    "from person import Person\n",
    "lines = spark.sparkContext.textFile(\"adult.data\").filter(lambda l: len(l)>0 and l.find(\"?\")<0)\n",
    "data = lines.map(lambda line: Person(line.split(\", \")))\n",
    "\n",
    "# testing\n",
    "print(data.count())\n",
    "print(data.first())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d297360-7c69-49ff-8a16-eda84a10dfdc",
   "metadata": {},
   "source": [
    "# Task 10."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4cfb653-526d-4df1-ac37-0a349fa0648d",
   "metadata": {},
   "source": [
    "### 10.1. Womens from Mexico with HS-grad education."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0a401035-d871-4086-b05a-4cb27237bfb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{23, Mexico, HS-grad...},\n",
       " {31, Mexico, HS-grad...},\n",
       " {32, Mexico, HS-grad...},\n",
       " {53, Mexico, HS-grad...},\n",
       " {29, Mexico, HS-grad...},\n",
       " {40, Mexico, HS-grad...},\n",
       " {20, Mexico, HS-grad...},\n",
       " {26, Mexico, HS-grad...},\n",
       " {20, Mexico, HS-grad...},\n",
       " {25, Mexico, HS-grad...},\n",
       " {56, Mexico, HS-grad...},\n",
       " {24, Mexico, HS-grad...},\n",
       " {20, Mexico, HS-grad...},\n",
       " {29, Mexico, HS-grad...},\n",
       " {25, Mexico, HS-grad...},\n",
       " {20, Mexico, HS-grad...},\n",
       " {22, Mexico, HS-grad...},\n",
       " {31, Mexico, HS-grad...},\n",
       " {30, Mexico, HS-grad...},\n",
       " {26, Mexico, HS-grad...},\n",
       " {26, Mexico, HS-grad...},\n",
       " {27, Mexico, HS-grad...},\n",
       " {25, Mexico, HS-grad...},\n",
       " {34, Mexico, HS-grad...},\n",
       " {37, Mexico, HS-grad...},\n",
       " {41, Mexico, HS-grad...},\n",
       " {22, Mexico, HS-grad...},\n",
       " {51, Mexico, HS-grad...},\n",
       " {20, Mexico, HS-grad...},\n",
       " {22, Mexico, HS-grad...},\n",
       " {28, Mexico, HS-grad...},\n",
       " {33, Mexico, HS-grad...},\n",
       " {24, Mexico, HS-grad...}]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.filter(lambda o: o.sex==\"Female\" and o.nativeCountry==\"Mexico\" and o.education==\"HS-grad\").collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4a35539-b9eb-4c60-8258-453fea1326aa",
   "metadata": {},
   "source": [
    "### 10.2. Number of womens and men who took part in the census."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b3e39bbb-1f06-4c6e-9f85-69586142a780",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----------+\n",
      "|   sex|count(sex)|\n",
      "+------+----------+\n",
      "|Female|      9782|\n",
      "|  Male|     20380|\n",
      "+------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.createDataFrame(data)\n",
    "df.groupBy(\"sex\").agg(count(\"sex\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c328d92a-2c25-417d-9ec3-a953f1cf5848",
   "metadata": {},
   "source": [
    "### 10.3. Average age of people with marital status \"Never-married\" and workclass \"Private\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "61dee968-774c-4bfd-a719-2623b22cf376",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "|       Average age|\n",
      "+------------------+\n",
      "|27.633520249221185|\n",
      "+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter((df.maritalStatus==\"Never-married\") & (df.workclass==\"Private\")).agg(avg(\"age\").alias(\"Average age\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b8b122d-f377-473b-b3f1-796e39d15a1f",
   "metadata": {},
   "source": [
    "### 10.4. Number of people with a numerical education of 9 to 13 working 20 to 30 hours a week grouped by workclass."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "067081c9-7bd5-49c6-aa71-d9bf0200938c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+----------------+\n",
      "|       workclass|Number of people|\n",
      "+----------------+----------------+\n",
      "|Self-emp-not-inc|             223|\n",
      "|       Local-gov|             104|\n",
      "|       State-gov|              85|\n",
      "|         Private|            1842|\n",
      "|     Without-pay|               5|\n",
      "|     Federal-gov|              27|\n",
      "|    Self-emp-inc|              47|\n",
      "+----------------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter(((df.educationNum>=9)&(df.educationNum<=13))&((df.hoursPerWeek>=20)&(df.hoursPerWeek<=30))).groupBy(\"workclass\").agg(count(\"workclass\").alias(\"Number of people\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "312811c0-f215-459f-a07b-a9dbf392260c",
   "metadata": {},
   "source": [
    "### 10.5. Numbers of people from the US with the same education."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c27c39e5-24a3-4a14-85cf-c2c7e6feb00b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+----------------+\n",
      "|   education|Number of people|\n",
      "+------------+----------------+\n",
      "|     Masters|            1484|\n",
      "|        10th|             752|\n",
      "|     5th-6th|              78|\n",
      "|  Assoc-acdm|             939|\n",
      "|   Assoc-voc|            1233|\n",
      "|     7th-8th|             437|\n",
      "|         9th|             350|\n",
      "|     HS-grad|            9209|\n",
      "|   Bachelors|            4618|\n",
      "|        11th|             957|\n",
      "|     1st-4th|              39|\n",
      "|   Preschool|              15|\n",
      "|        12th|             331|\n",
      "|   Doctorate|             314|\n",
      "|Some-college|            6260|\n",
      "| Prof-school|             488|\n",
      "+------------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter(df.nativeCountry==\"United-States\").groupBy(\"education\").agg(count(\"education\").alias(\"Number of people\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b26fce3-1828-4118-92b2-d4f70178b53a",
   "metadata": {},
   "source": [
    "### 10.6. Average age of people with gain class \">50K\" in each occupation group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "31a68af2-e88a-4c4b-89f2-c8048426427b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+------------------+\n",
      "|       occupation|       Average age|\n",
      "+-----------------+------------------+\n",
      "|            Sales| 44.35876288659794|\n",
      "|  Exec-managerial|44.893649974186886|\n",
      "|   Prof-specialty|43.600220872446165|\n",
      "|Handlers-cleaners| 43.24096385542169|\n",
      "|  Farming-fishing| 47.06086956521739|\n",
      "|     Craft-repair| 43.73568281938326|\n",
      "| Transport-moving| 44.51724137931034|\n",
      "|  Protective-serv| 41.48095238095238|\n",
      "|    Other-service|41.371212121212125|\n",
      "|     Tech-support| 43.14028776978417|\n",
      "|Machine-op-inspct| 42.29795918367347|\n",
      "|     Adm-clerical|43.299196787148595|\n",
      "|  Priv-house-serv|              47.0|\n",
      "|     Armed-Forces|              46.0|\n",
      "+-----------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter(df.gainClass==\">50K\").groupBy(\"occupation\").agg(avg(\"age\").alias(\"Average age\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ace54ce1-53db-4b5d-9047-a2d2e7b04537",
   "metadata": {},
   "source": [
    "# Close spark session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "07f75704-6b14-4fd9-bda1-cf340014cc1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f95e2269-2baf-4926-a40b-1fbb9897543b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
